{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "7310e46f",
   "metadata": {},
   "outputs": [
    {
     "ename": "ModuleNotFoundError",
     "evalue": "No module named 'tensorflow'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
      "\u001b[1;32m~\\AppData\\Local\\Temp\\ipykernel_1736\\2262271350.py\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[1;32mfrom\u001b[0m \u001b[0mkeras\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mapplications\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mvgg16\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mVGG16\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      2\u001b[0m \u001b[1;31m#load model\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      3\u001b[0m \u001b[0mmodel\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mVGG16\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      4\u001b[0m \u001b[1;31m#summarize the model\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\keras\\__init__.py\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m     18\u001b[0m \u001b[1;33m[\u001b[0m\u001b[0mkeras\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mio\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mhttps\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m//\u001b[0m\u001b[0mkeras\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mio\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     19\u001b[0m \"\"\"\n\u001b[1;32m---> 20\u001b[1;33m \u001b[1;32mfrom\u001b[0m \u001b[0mkeras\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mdistribute\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     21\u001b[0m \u001b[1;32mfrom\u001b[0m \u001b[0mkeras\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mmodels\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     22\u001b[0m \u001b[1;32mfrom\u001b[0m \u001b[0mkeras\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mengine\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0minput_layer\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mInput\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\keras\\distribute\\__init__.py\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m     16\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     17\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 18\u001b[1;33m \u001b[1;32mfrom\u001b[0m \u001b[0mkeras\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdistribute\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0msidecar_evaluator\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\keras\\distribute\\sidecar_evaluator.py\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m     15\u001b[0m \u001b[1;34m\"\"\"Python module for evaluation loop.\"\"\"\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     16\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 17\u001b[1;33m \u001b[1;32mimport\u001b[0m \u001b[0mtensorflow\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcompat\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mv2\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0mtf\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     18\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     19\u001b[0m \u001b[1;31m# isort: off\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mModuleNotFoundError\u001b[0m: No module named 'tensorflow'"
     ]
    }
   ],
   "source": [
    "from keras.applications.vgg16 import VGG16\n",
    "#load model\n",
    "model=VGG16()\n",
    "#summarize the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "02bd2079",
   "metadata": {},
   "outputs": [],
   "source": [
    "#the model can then used to directly to classify into one of 10000 classes\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "84968141",
   "metadata": {},
   "outputs": [],
   "source": [
    "#importing tensorflow\n",
    "from keras.layers import Input, Lambda, Dense, Flatten\n",
    "from keras.models import Model\n",
    "from keras.applications.vgg16 import VGG16\n",
    "from keras.applications.vgg16 import preprocess_input\n",
    "from keras.preprocessing import image\n",
    "from keras.preprocessing.image import ImageDataGenerator\n",
    "from keras.models import Sequential\n",
    "from keras_preprocessing.image import load_img\n",
    "from keras_preprocessing.image import img_to_array\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from glob import glob\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "#import os\n",
    "#os.listdir()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "699664ae",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_path = 'C:/Users/Gayathri/OneDrive/Documents/Cartoon Detection System/VGG16/train dataset'\n",
    "valid_path = 'C:/Users/Gayathri/OneDrive/Documents/Cartoon Detection System/VGG16/test'\n",
    "#add preprocessing layer to the front of VGG\n",
    "vgg = VGG16(input_shape = [224,224,3], weights = 'imagenet', include_top = False)\n",
    "#don't train rxisting weights\n",
    "for layer in vgg.layers:\n",
    "    layer.trainable = False\n",
    "#useful for getting number of classes\n",
    "folders = glob('C:/Users/Gayathri/OneDrive/Documents/train dataset/*')\n",
    "x =  Flatten()(vgg.output)\n",
    "prediction = Dense(len(folders), activation='softmax')(x)\n",
    "#create model object\n",
    "model = Model(inputs = vgg.input, outputs = prediction)\n",
    "#view the structure of the model\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3ff8d4c1",
   "metadata": {},
   "outputs": [],
   "source": [
    "model.compile(\n",
    "        loss = 'categorical_crossentropy',\n",
    "        optimizer = 'adam',\n",
    "        metrics = ['accuracy']\n",
    "        )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3107b507",
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.preprocessing.image import ImageDataGenerator\n",
    "\n",
    "train_datagen = ImageDataGenerator(rescale= 1./255,\n",
    "                                   shear_range= 0.2,\n",
    "                                   zoom_range= 0.2,\n",
    "                                   horizontal_flip= True)\n",
    "\n",
    "test_datagen = ImageDataGenerator(rescale= 1./255)\n",
    "\n",
    "\n",
    "\n",
    "training_set = train_datagen.flow_from_directory('C:/Users/Gayathri/OneDrive/Documents/Cartoon Detection System/VGG16/train dataset',\n",
    "                                                       target_size= (224,224),\n",
    "                                                       batch_size=32,\n",
    "                                                       class_mode='categorical')\n",
    "\n",
    "test_set = test_datagen.flow_from_directory('C:/Users/Gayathri/OneDrive/Documents/Cartoon Detection System/VGG16/test',\n",
    "                                            target_size= (224,224),\n",
    "                                            batch_size=32,\n",
    "                                            class_mode= 'categorical')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "72cf3b02",
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras_preprocessing.image import load_img\n",
    "from keras_preprocessing.image import img_to_array\n",
    "import matplotlib.pyplot as plt\n",
    "# load an image from file\n",
    "image = load_img('C:/Users/Gayathri/OneDrive/Documents/Cartoon Detection System/VGG16/train dataset/Shiori Fujisaki/sf1.jpg', target_size=(224, 224))\n",
    "# convert the image pixels to a numpy array\n",
    "image = img_to_array(image)\n",
    "plt.imshow(image)\n",
    "# this is label one(Animated)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0878317f",
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras_preprocessing.image import load_img\n",
    "from keras_preprocessing.image import img_to_array\n",
    "import matplotlib.pyplot as plt\n",
    "# load an image from file\n",
    "image = load_img('C:/Users/Gayathri/OneDrive/Documents/Cartoon Detection System/VGG16/train dataset/Ena/ena1.jpg', target_size=(224, 224))\n",
    "# convert the image pixels to a numpy array\n",
    "image = img_to_array(image)\n",
    "plt.imshow(image)\n",
    "# this is label one(Animated)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "162cef36",
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras_preprocessing.image import load_img\n",
    "from keras_preprocessing.image import img_to_array\n",
    "import matplotlib.pyplot as plt\n",
    "# load an image from file\n",
    "image = load_img('C:/Users/Gayathri/OneDrive/Documents/Cartoon Detection System/VGG16/train dataset/kanon/kanon2.jpg', target_size=(224, 224))\n",
    "# convert the image pixels to a numpy array\n",
    "image = img_to_array(image)\n",
    "plt.imshow(image)\n",
    "# this is label one(Animated)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bcf4604d",
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras_preprocessing.image import load_img\n",
    "from keras_preprocessing.image import img_to_array\n",
    "import matplotlib.pyplot as plt\n",
    "# load an image from file\n",
    "image = load_img('C:/Users/Gayathri/OneDrive/Documents/Cartoon Detection System/VGG16/train dataset/Kiyotaka/KA1.jpg', target_size=(224, 224))\n",
    "# convert the image pixels to a numpy array\n",
    "image = img_to_array(image)\n",
    "plt.imshow(image)\n",
    "# this is label one(Animated)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "96097271",
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras_preprocessing.image import load_img\n",
    "from keras_preprocessing.image import img_to_array\n",
    "import matplotlib.pyplot as plt\n",
    "# load an image from file\n",
    "image = load_img('C:/Users/Gayathri/OneDrive/Documents/Cartoon Detection System/VGG16/train dataset/Kudou Fuyuka/KF5.jpg', target_size=(224, 224))\n",
    "# convert the image pixels to a numpy array\n",
    "image = img_to_array(image)\n",
    "plt.imshow(image)\n",
    "# this is label one(Animated)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "894d9c9d",
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras_preprocessing.image import load_img\n",
    "from keras_preprocessing.image import img_to_array\n",
    "import matplotlib.pyplot as plt\n",
    "# load an image from file\n",
    "image = load_img('C:/Users/Gayathri/OneDrive/Documents/Cartoon Detection System/VGG16/train dataset/nami/nami1.jpg', target_size=(224, 224))\n",
    "# convert the image pixels to a numpy array\n",
    "image = img_to_array(image)\n",
    "plt.imshow(image)\n",
    "# this is label one(Animated)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c77c93b6",
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras_preprocessing.image import load_img\n",
    "from keras_preprocessing.image import img_to_array\n",
    "import matplotlib.pyplot as plt\n",
    "# load an image from file\n",
    "image = load_img('C:/Users/Gayathri/OneDrive/Documents/Cartoon Detection System/VGG16/train dataset/Rikka/RT1.jpg', target_size=(224, 224))\n",
    "# convert the image pixels to a numpy array\n",
    "image = img_to_array(image)\n",
    "plt.imshow(image)\n",
    "# this is label one(Animated)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bf34b4fa",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "from keras_preprocessing.image import load_img\n",
    "from keras_preprocessing.image import img_to_array\n",
    "import matplotlib.pyplot as plt\n",
    "# load an image from file\n",
    "image = load_img('C:/Users/Gayathri/OneDrive/Documents/Cartoon Detection System/VGG16/train dataset/Misuzu/Mis1.jpg', target_size=(224, 224))\n",
    "# convert the image pixels to a numpy array\n",
    "image = img_to_array(image)\n",
    "plt.imshow(image)\n",
    "# this is label one(Animated)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1f4afdb4",
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras_preprocessing.image import load_img\n",
    "from keras_preprocessing.image import img_to_array\n",
    "import matplotlib.pyplot as plt\n",
    "# load an image from file\n",
    "image = load_img('C:/Users/Gayathri/OneDrive/Documents/Cartoon Detection System/VGG16/train dataset/Sane/Sane1.jpg', target_size=(224, 224))\n",
    "# convert the image pixels to a numpy array\n",
    "image = img_to_array(image)\n",
    "plt.imshow(image)\n",
    "# this is label one(Animated)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7dc36d80",
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras_preprocessing.image import load_img\n",
    "from keras_preprocessing.image import img_to_array\n",
    "import matplotlib.pyplot as plt\n",
    "# load an image from file\n",
    "image = load_img('C:/Users/Gayathri/OneDrive/Documents/Cartoon Detection System/VGG16/train dataset/Syaoran Li/SL1.jpg', target_size=(224, 224))\n",
    "# convert the image pixels to a numpy array\n",
    "image = img_to_array(image)\n",
    "plt.imshow(image)\n",
    "# this is label one(Animated)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4eabe257",
   "metadata": {},
   "outputs": [],
   "source": [
    "r = model.fit_generator(\n",
    "        training_set,\n",
    "        validation_data= test_set,\n",
    "        epochs=5,\n",
    "        steps_per_epoch= len(training_set),\n",
    "        validation_steps=len(test_set)\n",
    "        )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "07442459",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.plot(r.history['loss'], label = 'train loss')\n",
    "plt.plot(r.history['val_loss'], label = 'val loss')\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d60471bc",
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.layers import Input, Lambda, Dense, Flatten\n",
    "from keras.models import Model\n",
    "from keras_preprocessing.image import load_img\n",
    "\n",
    "image = load_img('C:/Users/Gayathri/OneDrive/Documents/test/animated image/a1.png', target_size=(224, 224))\n",
    "# convert the image pixels to a numpy array\n",
    "image = img_to_array(image)\n",
    "# reshape data for the model\n",
    "image = image.reshape((1, image.shape[0], image.shape[1], image.shape[2]))\n",
    "# prepare the image for the VGG model\n",
    "image = preprocess_input(image)\n",
    "# predict the probability across all output classes\n",
    "yhat = model.predict(image)\n",
    "yhat"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "69c22fa3",
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.layers import Input, Lambda, Dense, Flatten\n",
    "from keras.models import Model\n",
    "from keras_preprocessing.image import load_img\n",
    "\n",
    "image = load_img('C:/Users/Gayathri/OneDrive/Documents/test/animated image/a1.png', target_size=(224, 224))\n",
    "# convert the image pixels to a numpy array\n",
    "image = img_to_array(image)\n",
    "# reshape data for the model\n",
    "image = image.reshape((1, image.shape[0], image.shape[1], image.shape[2]))\n",
    "# prepare the image for the VGG model\n",
    "image = preprocess_input(image)\n",
    "\n",
    "rgb = cv2.cvtColor(image, cv2.COLOR_BGR2RGB)\n",
    "\n",
    "    # try to detect faces in the webcam\n",
    "faces = face_cascade.detectMultiScale(rgb, scaleFactor=1.3, minNeighbors=5)\n",
    "\n",
    "    # for each faces found\n",
    "for (x, y, w, h) in faces:\n",
    "    # Draw a rectangle around the face\n",
    "    color = (0, 255, 255) # in BGR\n",
    "    stroke = 5\n",
    "    cv2.rectangle(frame, (x, y), (x + w, y + h), color, stroke)\n",
    "    cv2.putText(img, \"Cartoon Spotted\", (x, y), cv2.FONT_HERSHEY_SIMPLEX,\n",
    "             0.75, (0, 255, 0), 2)\n",
    "cv2.imshow(\"image\", image)\n",
    "cv2.waitKey(0)\n",
    " \n",
    "# It is for removing/deleting created GUI window from screen\n",
    "# and memory\n",
    "cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "13402977",
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.models import load_model\n",
    "model.save('Final_Model_Face.h5')\n",
    "print('Successfully saved')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
